---
title: Linear and Nonlinear Regression
author: Hoda Alemrajabi
date: '2023-11-05'
categories:
  - news
  - code
  - analysis
  - data visualization
image: third post.png
jupyter:
  jupytext:
    formats: 'ipynb,qmd'
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

This post is about linear and nonlinear regression in ML!

![](third%20post.png){width="366"}

Linear and nonlinear regression are important concepts in machine learning for modeling relationships between variables. In this post, I created an example in Python to visualize both linear and nonlinear regression.

I used the following approach:

-   **Generate Synthetic Data**: Creating a dataset that has a nonlinear relationship.

-   **Linear Regression**: Applying a linear regression model to this data.

-   **Nonlinear Regression**: Applying a nonlinear regression model, like polynomial regression.

-   **Visualization**: Plotting both the linear and nonlinear regression models along with the data.

Here's the Python code for this:

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Generate synthetic data
np.random.seed(0)
X = 2 - 3 * np.random.normal(0, 1, 20)
y = X - 2 * (X ** 2) + np.random.normal(-3, 3, 20)

# Reshaping and sorting the data based on X
X = X[:, np.newaxis]
sort_index = X.flatten().argsort()  # Get the sorted order of indices
X = X[sort_index]
y = y[sort_index]

# Linear Regression
linear_regressor = LinearRegression()
linear_regressor.fit(X, y)
y_pred_linear = linear_regressor.predict(X)

# Nonlinear Regression (Polynomial)
degree = 2
polyreg = make_pipeline(PolynomialFeatures(degree), LinearRegression())
polyreg.fit(X, y)
y_pred_poly = polyreg.predict(X)

# Visualization
plt.scatter(X, y, color='black', label='Data')
plt.plot(X, y_pred_linear, color='blue', label='Linear Regression')
plt.plot(X, y_pred_poly, color='red', label='Nonlinear Regression')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear vs Nonlinear Regression')
plt.legend()
plt.show()
```

Running this code shows us a plot where you can see how linear regression fails to capture the complexity of the data, while the polynomial regression provides a better fit, illustrating the concept of linear and nonlinear regression in machine learning.
