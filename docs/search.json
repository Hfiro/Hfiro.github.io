[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "This is the first post in the Quarto blog of Hoda Alemrajabi . Welcome!\n\nIn this post, I will talk about Probability theory and random variables.\nIn this topic, one common concept is the visualization of different probability distributions, which are fundamental in understanding random variables. Here’s an example where I visualized a Normal (Gaussian) distribution, which is a cornerstone in probability theory and often used in machine learning:\n\nGenerating Random Data: I used numpy to generate random data following a normal distribution.\nVisualization: I used matplotlib to plot the histogram of this data to visualize the distribution.\n\nHere’s the Python code to do this:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate random data from a normal distribution\nmu, sigma = 0, 0.1  # mean and standard deviation\ns = np.random.normal(mu, sigma, 1000)\n\n# Create the histogram of the data\ncount, bins, ignored = plt.hist(s, 30, density=True)\n\n# Plot the distribution curve\nplt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n               np.exp(- (bins - mu)**2 / (2 * sigma**2)),\n         linewidth=2, color='r')\nplt.title('Normal Distribution (Gaussian)')\nplt.xlabel('Value')\nplt.ylabel('Probability Density')\nplt.show()\n\n\n\n\nRunning this code will give us a graphical representation of a normal distribution, which is an essential concept in probability theory related to random variables. We can modify mu and sigma to see how the distribution changes. This kind of visualization is particularly useful in understanding data distributions in machine learning."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hfiro.github.io",
    "section": "",
    "text": "Linear and Nonlinear Regression\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2023\n\n\nHoda Alemrajabi\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nHoda Alemrajabi\n\n\n\n\n\n\n  \n\n\n\n\nProbability Theory and Random Variables\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2023\n\n\nHoda Alemrajabi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Clustering",
    "section": "",
    "text": "In this post, I will talk about clustering in ML!\n\nClustering is a fundamental concept in machine learning, particularly in unsupervised learning. A common method for clustering is the K-Means algorithm. We can visualize clustering by using Python with libraries such as matplotlib for plotting and sklearn for machine learning functionalities.\nHere’s an example of a Python script that generates random data, applies the K-Means clustering algorithm, and visualizes the results:\n\nGenerate Random Data: Creating a dataset with random points.\nApply K-Means Clustering: Using the K-Means algorithm to identify clusters in the data.\nVisualization: Plotting the data points and color them according to their cluster.\n\nHere’s the Python code:\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n\n# Generate random data\nn_samples = 300\nn_features = 2\ncenters = 4\nX, y_true = make_blobs(n_samples=n_samples, n_features=n_features, centers=centers)\n\n# Apply K-Means Clustering\nkmeans = KMeans(n_clusters=centers)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\n# Visualization\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\nplt.title('K-Means Clustering')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.show()\n\nC:\\Users\\hodaa\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n\nThe default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n\nC:\\Users\\hodaa\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n\nKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n\n\n\n\n\n\nRunning this code will give usa visual representation of the clustered data points, showing how K-Means algorithm groups the data into distinct clusters. This is a simple yet effective way to understand the concept of clustering in machine learning."
  },
  {
    "objectID": "posts/post-with-code/Untitled.html",
    "href": "posts/post-with-code/Untitled.html",
    "title": "Hfiro.github.io",
    "section": "",
    "text": "%pip install jupytext\n\nCollecting jupytext\n  Obtaining dependency information for jupytext from https://files.pythonhosted.org/packages/9e/e3/3c5b6cce216d090ed6cf6cc258602f836d050738ac02f97cb71675f9cfe3/jupytext-1.15.2-py3-none-any.whl.metadata\n  Downloading jupytext-1.15.2-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: nbformat in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupytext) (5.7.0)\nRequirement already satisfied: pyyaml in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupytext) (6.0)\nRequirement already satisfied: toml in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupytext) (0.10.2)\nRequirement already satisfied: markdown-it-py&gt;=1.0.0 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupytext) (2.2.0)\nRequirement already satisfied: mdit-py-plugins in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupytext) (0.3.0)\nRequirement already satisfied: mdurl~=0.1 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from markdown-it-py&gt;=1.0.0-&gt;jupytext) (0.1.0)\nRequirement already satisfied: fastjsonschema in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from nbformat-&gt;jupytext) (2.16.2)\nRequirement already satisfied: jsonschema&gt;=2.6 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from nbformat-&gt;jupytext) (4.17.3)\nRequirement already satisfied: jupyter-core in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from nbformat-&gt;jupytext) (5.3.0)\nRequirement already satisfied: traitlets&gt;=5.1 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from nbformat-&gt;jupytext) (5.7.1)\nRequirement already satisfied: attrs&gt;=17.4.0 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;jupytext) (22.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;jupytext) (0.18.0)\nRequirement already satisfied: platformdirs&gt;=2.5 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupyter-core-&gt;nbformat-&gt;jupytext) (2.5.2)\nRequirement already satisfied: pywin32&gt;=300 in c:\\users\\hodaa\\anaconda3\\lib\\site-packages (from jupyter-core-&gt;nbformat-&gt;jupytext) (305.1)\nDownloading jupytext-1.15.2-py3-none-any.whl (307 kB)\n   ---------------------------------------- 0.0/307.2 kB ? eta -:--:--\n   - -------------------------------------- 10.2/307.2 kB ? eta -:--:--\n   - -------------------------------------- 10.2/307.2 kB ? eta -:--:--\n   ------- ------------------------------- 61.4/307.2 kB 409.6 kB/s eta 0:00:01\n   ------------- ------------------------ 112.6/307.2 kB 656.4 kB/s eta 0:00:01\n   --------------------- ---------------- 174.1/307.2 kB 807.1 kB/s eta 0:00:01\n   ------------------------------- ------ 256.0/307.2 kB 983.0 kB/s eta 0:00:01\n   -------------------------------------- 307.2/307.2 kB 999.9 kB/s eta 0:00:00\nInstalling collected packages: jupytext\nSuccessfully installed jupytext-1.15.2\nNote: you may need to restart the kernel to use updated packages."
  }
]